{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmhoh4bzRuWcuwXOxwHWe5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willdone1337/NLP_poetry_generator/blob/master/markovify_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV8mbtVzANzO",
        "outputId": "87ca0b96-c6b5-49ce-86de-ad2e6e89b069"
      },
      "source": [
        "#Loading the model from pickle file\n",
        "import numpy as np\n",
        "from flask import Flask, request, make_response\n",
        "import json\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "import re\n",
        "import os.path\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "import pandas as pd\n",
        "from tensorflow.keras import regularizers\n",
        "import numpy as np\n",
        "from keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.layers import LSTM, Dense, Dropout, Flatten\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gJ0EOP6ZVCr",
        "outputId": "9dd60731-ee3a-44e1-87e9-d8a4d20f93a9"
      },
      "source": [
        "!pip install markovify\n",
        "import markovify\n",
        "import random"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: markovify in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from markovify) (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeYpoGk6ZiCK",
        "outputId": "0c39d06c-c715-4e8a-d4ea-8f931328219d"
      },
      "source": [
        "data = open('/content/gdrive/MyDrive/models/nizami_books.txt',encoding='utf-8').read().lower().split('\\n')\n",
        "data=list(data)\n",
        "model=markovify.NewlineText(data)\n",
        "import numpy as np\n",
        "\n",
        "for i in range(5):\n",
        "    print()\n",
        "    for i in range(random.randrange(1, 4)):\n",
        "        print(model.make_short_sentence(30))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "bil ki, bu dünyada biz,\n",
            "qərəzli bir sövda daşı,\n",
            "yadında bir neçə ağac,\n",
            "\n",
            "təklikdə ağlardı o gözəl pəri.\n",
            "\n",
            "None\n",
            "bir quş idi o gün.\n",
            "None\n",
            "\n",
            "None\n",
            "\n",
            "gəl bu yerdə bir dəm.\n",
            "özün də o sinəndədir.\n",
            "elə ki, başa çatdı birtəhər,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNDj1H2zajVA",
        "outputId": "b5441b1f-83b4-40f8-936e-7b47d3d285af"
      },
      "source": [
        "chars = (set(data))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "vocab_size = len(chars)\n",
        "print('Vocabulary size: {}'.format(vocab_size))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 14529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ed7k8aBbyz1",
        "outputId": "d8b6efe1-cfca-4419-ed73-784954f29cc1"
      },
      "source": [
        "X = [] \n",
        "Y = [] \n",
        "\n",
        "length = len(data)\n",
        "seq_length = 100\n",
        "\n",
        "for i in range(0, length - seq_length, 1):\n",
        "    sequence = data[i:i + seq_length]\n",
        "    label = data[i + seq_length]\n",
        "    X.append([char_indices[char] for char in sequence])\n",
        "    Y.append(char_indices[label])\n",
        "\n",
        "print('NUum of seq: {}'.format(len(X)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUum of seq: 15506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfENkPB0cBxP",
        "outputId": "dc72d6ae-6adc-4dc5-d552-5724a0711e7c"
      },
      "source": [
        "X_new = np.reshape(X, (len(X), seq_length, 1))\n",
        "X_new = X_new/float(len(chars))\n",
        "Y_new = np_utils.to_categorical(Y)\n",
        "\n",
        "X_new.shape, Y_new.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15506, 100, 1), (15506, 14529))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-lTR7XqcP2a",
        "outputId": "67a3e9c0-1e63-4cd5-d142-8df104ddb4d9"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(150, input_shape = (X_new.shape[1], X_new.shape[2]), return_sequences = True))\n",
        "\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(Y_new.shape[1], activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "\n",
        "model.fit(X_new, Y_new, epochs = 1, verbose = 1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "485/485 [==============================] - 61s 59ms/step - loss: 9.5233\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6d9c9ad6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J-Cy4w9cwVB",
        "outputId": "ffb10091-0ec3-4696-f75a-978f02c6c672"
      },
      "source": [
        "start = np.random.randint(0, len(X)-1)\n",
        "string_mapped = list(X[start])\n",
        "full_string = [indices_char[value] for value in string_mapped]\n",
        "\n",
        "# Generate text\n",
        "for i in range(30):\n",
        "    x = np.reshape(string_mapped, (1, len(string_mapped), 1))\n",
        "    x = x / float(len(chars))\n",
        "    \n",
        "    pred_index = np.argmax(model.predict(x, verbose = 0))\n",
        "    seq = [indices_char[value] for value in string_mapped]\n",
        "    full_string.append(indices_char[pred_index])\n",
        "    \n",
        "    string_mapped.append(pred_index)\n",
        "    string_mapped = string_mapped[1:len(string_mapped)]\n",
        "    \n",
        "# Combine text\n",
        "newtext = 'əgər '\n",
        "for char in full_string:\n",
        "    newtext = newtext + char\n",
        "\n",
        "print(newtext)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "əgər sənin məhrəmindir bu gözəl can da.səndən söz yaratmaq gözlənsin gərək,məndən dua etmək, bəxtdən də kömək\",danışıb qurtardı o ciyərparam,onun xatirinə söz aldı ilham.gövhər axtarmağa başladım yenə,kimyalar açaraq girdim mədənə.təbim də ən qısa bir yol axtardı,yol uzunluğundan qorxum da vardı.nə bundan qısaca yol var hələlik,nə də bundan qıvraq, iti bir minik.bəhrin suyu yüngül, özü axardır,canlı, nəfəs alan balığı vardırçox bu şirinlikdə söz deyən olar,sanma ki, onlarda bu təzəlik var.hələ üzücülər qəlb dənizindənbelə saf bir inci tapmamış, bilsən.hər beyti, sapdakı incilər kimi,parlayır eybsiz bir hünər kimi.mən bu inciləri gəzəndə bir-bir,ayağım tük qədər sürüşməmişdir.qəlb cavab- verirdi mənə ürəkdən,bulaq su verirdi yer qazdıqca mən.əqildən aldığım bu gəlir, dövlətyalnız əsərimə vururdu zinət.dörd min beytdən də çoxdur bu dastan,dörd aydan az vaxta yazmışam, inan!əgər başqa işlər olsaydı haram,bu, on dörd gecəyə olardı tamam.bu azad gəlini görən şad olsun,ona abad deyən, qoy abad olsun.s. f. d. ili idi rəcəbin sonu46,çox gözəl şəkildə bəzədim onu.əgər tarixini söyləsəm əyan,dörd il keçmiş idi beş yüz həştaddan.sənətin əlilə tutdum bəzəyə,gətirib oturtdum bu kəcavəyə.şahımın mübarək gözündən başqa,kimsənin nəzəri dəyməsin ona.sən şahlıq taxtının şahsüvarısan,qaranın və ağın hökmdarısan.tac sahiblərinin başçısısan sən,şahlar ordusunun sərkərdəsisən.ey şahlar içində mütləq olan şah!ey dünya xaqanı, böyük padişah!şöhrətin tutmuşdur bütün mahalı,dinin və dövlətin sənsən calalı.şahlığın taxtını sənsən saxlayan,hökmünə baş əyir bu yer, bu ümman.şahların tacısan, əbülmüzəffər,yeddi məmləkətə sən oldun zivər.kölgən bir günəşdir, sən alov kimi,keyqubad rütbəli keyxosrov kimi.adın axsitandır, özün söz bilən,göydəki günəşin ağasısan sən.sən ki, padişahsan, açıq, aşikar,gizli xəlifəsən, böyük hökmüdar.bu bəhram nəsəbli, ülkər üzlü sən47,məlik mənuçehrin sədəf dürrüsən.bu tayfa şahlığı nəsildən-nəslə,gəlib keçə-keçə oldu silsilə.onun şah əcdadı aransa əgər,şahdan-şaha gedir adəmə qədər,istərəm, bu böyük şahda daima,qılınc uzun olsun, qələmsə qısa.daimi bir taxtda o bərqərardır.ağıl tək nöqsansız bir hökmüdardır.o, yeddi göylərə boyun əyməyənyeddi ərənlərə qiblədir, bilsən.ruzi verən deyil, ruzi göyüdür,dünyanın sərdarı, həm böyüyüdür,mənalar çeşməsi gözündə qaynar,qəlbində göylərin gizli sirri var.on iki elmin də sirrləri bütünəlində mum kimi yumşalır hər gün.bu yeddi örtüklü, altı barmaqlı,bir gözlü, dörd əlli, doqquz ayaqlıonun çəmbərindən çıxmasın deyə,qalıb çəmbərində dönmüş həlqəyə.adı şirin sulu bir kainatdır,varlığı aləmə abi-həyatdır.dağılmış mədənlər onun əliylə,artmış kərəmindən dənizlər belə.bir yandan dünyanı tutur zəfəri,bir yandan əfv edir kərəm əlləri.cövhərli qılıncdan tutaraq çapar,yaxından ötəni vurar, qamçılar.bəxtinin burnunda kövsər suyu var,onun toppuzundan alovlar qalxar.o, dünya mülkünə böyük işıqdır,məclisə, meydana bir yaraşıqdır.mərrixdə bir qılınc, zöhrədə bir cam,sağında, solunda durmuşlar müdam.zöhrə şərab verir cam ilə ona,mərrix silah alıb düşür ardına.qılıncı qaldırır bir ləl dağı,camından tökülür ləl bulağı.bu iki qan rəngli lələ baxanda,ləlin rəngindədir şərab da, qan da.sübhün saqisidir onun kərəmi,başıyın üstəki fələyə bax sən,bil, nə qələm yeni bir mətləb yazar,bayraqdarı neylərik, sərkərdəmizsən özün.ətir saçan hörüklər zəncirdi şir qoluna.taki gül qonçası açsın bu taqda,əməlini göstərən bir güzgüdür həmişə.bil, nə qələm yeni bir mətləb yazar,ovunu öldürsə olarmı suçu?ətir saçan hörüklər zəncirdi şir qoluna.ki, dünya açmasın başına kələk.ki, dünya açmasın başına kələk.ki, dünya açmasın başına kələk.ki, dünya açmasın başına kələk.bayraqdarı neylərik, sərkərdəmizsən özün.bayraqdarı neylərik, sərkərdəmizsən özün.bayraqdarı neylərik, sərkərdəmizsən özün.bayraqdarı neylərik, sərkərdəmizsən özün.bayraqdarı neylərik, sərkərdəmizsən özün.ki, dünya açmasın başına kələk.ki, dünya açmasın başına kələk.ovunu öldürsə olarmı suçu?bayraqdarı neylərik, sərkərdəmizsən özün.bayraqdarı neylərik, sərkərdəmizsən özün.bayraqdarı neylərik, sərkərdəmizsən özün.bayraqdarı neylərik, sərkərdəmizsən özün.bil, nə qələm yeni bir mətləb yazar,ovunu öldürsə olarmı suçu?ovunu öldürsə olarmı suçu?bayraqdarı neylərik, sərkərdəmizsən özün.bayraqdarı neylərik, sərkərdəmizsən özün.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKc7hKBPdfZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49d8ed1-99f6-41f3-8e50-f59b10f539d1"
      },
      "source": [
        "import keras.utils as ku\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding\n",
        "\n",
        "# Lowercase all text\n",
        "\n",
        "\n",
        "# Create Tokenizer object to convert words to sequences of integers\n",
        "tokenizer = Tokenizer(num_words = None, filters = '#$%&(),*+-<=>@[\\\\]^_`{|}~\\t\\n', lower = False)\n",
        "\n",
        "# Train tokenizer to the texts\n",
        "tokenizer.fit_on_texts(data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert list of strings into flat dataset of sequences of tokens\n",
        "sequences = []\n",
        "for line in data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences to ensure equal lengths\n",
        "max_seq_len = max([len(x) for x in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen = max_seq_len, padding = 'pre'))\n",
        "\n",
        "# Create n-grams sequence predictors and labels\n",
        "predictors, label = sequences[:, :-1], sequences[:, -1]\n",
        "label = ku.to_categorical(label, num_classes = total_words)\n",
        "input_len = max_seq_len - 1\n",
        "################\n",
        "\"\"\"model = Sequential()\n",
        "model.add(Embedding(total_words, 50, input_length = input_len))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(total_words, activation = 'softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\"\"\"\n",
        "###############################################################################################\n",
        "\n",
        "\n",
        "model=load_model('/content/gdrive/MyDrive/models/nizamimodel_06loss.h5')\n",
        "model.summary()\n",
        "################# 0.6 categorical_Crossentropy loss with 100 epochs  ##########################\n",
        "\n",
        "#\n",
        "#model.fit(predictors, label, epochs = 100, verbose = 1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 9, 50)             1178450   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 150)               120600    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 23569)             3558919   \n",
            "=================================================================\n",
            "Total params: 4,857,969\n",
            "Trainable params: 4,857,969\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "QoZa5Uc5qCEb",
        "outputId": "dc6aabcc-0942-4526-d1db-3e4ae1b4e8db"
      },
      "source": [
        "def generate_line(text, next_words, max_seq_len, model):\n",
        "    for j in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen = max_seq_len - 1, padding = 'pre')\n",
        "        predicted = model.predict_classes(token_list, verbose = 0)\n",
        "        \n",
        "        output_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        text += ' ' + output_word\n",
        "    return text\n",
        "generate_line('səma',30,max_seq_len,model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'səma başının tacı yer üzü taxtın oldu. oldu. indi çöldə gecənin dar olum mən meydandı tapmasa sifətlər nədir? xeyri əhd keçən əlimdə mən. dürr heç var? heç zaman. gecətək qurda ölkəyə'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnes-yBp0rN1",
        "outputId": "af6ad9d8-cd36-4fa7-a8f8-dd9ba643ff38"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "data = open('/content/gdrive/MyDrive/models/nizami_books.txt',encoding='utf-8').read().lower().split('\\n')\n",
        "\n",
        "tokenizer=Tokenizer(num_words=3000)\n",
        "tokenizer.fit_on_texts(data)\n",
        "total_words=len(tokenizer.word_index)\n",
        "input_sequences=[]\n",
        "for line in data:\n",
        "    token_list=tokenizer.texts_to_sequences([line])[0]\n",
        "    for x in range(len(token_list)):\n",
        "        n_gram_seq=token_list[:x+1]\n",
        "        input_sequences.append(n_gram_seq)\n",
        "\n",
        "max_lenght=max([len(x) for x in input_sequences])\n",
        "padded_sequences=np.array(pad_sequences(input_sequences,maxlen=max_lenght,padding='pre'))\n",
        "x,y=padded_sequences[:,:-1],padded_sequences[:,-1]\n",
        "y=tf.keras.utils.to_categorical(y,num_classes=total_words)\n",
        "model = load_model('/content/gdrive/MyDrive/colabv2/trynizami_47percent.h5')\n",
        "\n",
        "def poem(x):\n",
        "    next_words=100\n",
        "    seed_text = ''\n",
        "    for _ in range(1, next_words + 1):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text + x])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_lenght - 1, padding='pre')\n",
        "        predicted = model.predict_classes(token_list, verbose=0)\n",
        "        output_word = ''\n",
        "        if _ % 4 == 0:\n",
        "            seed_text = seed_text + ','\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        # if _%4==0:\n",
        "        #   output_word+='\\n'\n",
        "        seed_text += ' ' + output_word\n",
        "\n",
        "    split_regex = re.compile(r'[,]')\n",
        "    sentences = [t.strip() for t in split_regex.split(seed_text)]\n",
        "    poem = []\n",
        "    for s in sentences:\n",
        "        poem.append(s)\n",
        "    alfa=''\n",
        "    for x in poem:\n",
        "        alfa+=x\n",
        "    return alfa\n",
        "\n",
        "print(poem('leyli'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 9).\n",
            "gül bir kimiaz şahıdır yoluna açmışdıoda bilsən inan inanolardı də dünyada indisən görək olubdur ondaşəfaət kişi göndər verənyandırar də bil ayaqüstə qərar nəfəs açıbdeyir qanad bu üstünəbaşı atdı onu onumən mən daha əzəldənlal deyil də abadsağam oldu mən ondannədir sənin qoca zəmanəçapdı hanı zənciri tökərəzəldən sona işi sənindərhal üzü çək şadsən də yaxşıdır bağışlaözünə onu birdən eyçatar qısa niyə mənbir deyil kəs olmuşdaha pis var vardıvardır əsər vardır yetirbudur onu bu boşqoca ağlardı sıxdı gərəkatdı\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV7ZiroVpyAR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
